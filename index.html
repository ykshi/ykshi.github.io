 <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>

<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />

<title>Yukai Shi </title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Yukai Shi</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://ykshi.github.io/"><img src="picture/syk1.jpg" alt="alt text" width="120px" /></a>&nbsp;</td>
<td align="left"><p>Associate Professor (with tenure)<br />
School of Information Engineering <br />
Guangdong University of Technology <br />
Higher Education Mega Center <br />
Guangzhou 510006, China <br />
Email: ykshi.1991 [at] foxmail [dot] com <br />
<br />
<a href="https://scholar.google.com/citations?user=z_tI-X4AAAAJ&hl=zh-CN">[Google Scholar]</a> 
  <a href="https://github.com/ykshi">[GitHub]</a>
  <a href="https://orcid.org/0000-0002-9413-6528">[ORCiD]</a>
   </p> <br />
</td>

</tr></table>

<h2>Biography</h2>
<p>Currently Dr. SHI is a teacher at Guangdong University of Technology (GDUT). Before that, he graduated from Sun Yat-Sen University with a PhD degree, supervised by Prof. <a href="http://www.linliang.net/">[Liang Lin (林倞教授)]</a>. He was a visiting student in the University of Sydney and Microsoft Research Asia,
worked with Prof.<a href="https://wlouyang.github.io/"> [Wanli Ouyang (欧阳万里教授)]</a> and Dr. <a href="https://jingdongwang2017.github.io/">[Jingdong Wang (王井东研究员)]</a>, respectively.  </p>

<p>His current research interests are mainly focus on the AIGC technology for vision alignment and augmentation. He serves as a Reviewer for a number of journals and conferences, such as IJCV, IEEE T-PAMI, T-NNLS, T-IP, T-MM, T-CSVT, CVPR, ICCV, ECCV, AAAI, etc. </p>

<i>Never stop looking for collaboration, please feel free to contact me via email. (any question/suggestion/collaboration)</i>

<h2>Research Topic</h2>
<ul>
<li><p><b>AI Generated Content (AIGC)</b>: <a href="https://mirrordiffusion.github.io/">Diffusion Model for Fantasy Generation.</a><br />
<li><p><b>Multimodality Sensing</b>: Cross-sensor Cooperative Sensing, Vision-Thermal Recognition, etc. <br />
<li><p><b>Computer Vision and Pattern Recognition</b>: Cross-data Vision Alignment, Data-centric Visual Learning, etc. <br />
</li>
</ul>

<h2>Selected Publications </h2> </b>
(<b>*</b> indicates supervised students) <a href="https://scholar.google.com/citations?user=z_tI-X4AAAAJ&hl=zh-CN">[Full Paper List]</a> 


<ul>
<li><p><a href="https://arxiv.org/pdf/2205.11131">  
Heterogeneous Semantic Transfer for Multi-label Recognition with Partial Labels</a> <br />
Tianshui Chen, Tao Pu, Lingbo Liu, <b>Yukai Shi</b>, Zhijing Yang, Liang Lin <br />
<i> International Journal of Computer Vision  <b>(IJCV)</b>, 2024. <a href="https://arxiv.org/pdf/2205.11131">[PDF]</a> <a href="https://github.com/HCPLab-SYSU/HCP-MLR-PL">[Code]</a><a href="https://mp.weixin.qq.com/s/oL7KKjKW3ZhCoXFIzxCJEg">[Media Report]</a></i></p> 

</ul>


<ul>
<li><p><a href="https://github.com/YupeiLin2388/Diff-Mosaic">  
Diff-Mosaic: Augmenting Realistic Representations in Infrared Small Target Detection via Diffusion Prior</a> <br />
<b>Yukai Shi</b>, Yupei Lin, Pengxu Wei, Xiaoyu Xian, Tianshui Chen, Liang Lin <br />
<i> IEEE Transactions on Geoscience and Remote Sensing  <b>(T-GRS)</b>, 2024. <a href="https://github.com/YupeiLin2388/Diff-Mosaic">[PDF]</a> <a href="https://github.com/YupeiLin2388/Diff-Mosaic">[Code]</a></i></p> 
</li><a href="https://github.com/YupeiLin2388/Diff-Mosaic">
<font color="#FF0000"> The Mosaic operation is renewed with diffusion prior, <span style="text-decoration: underline;"> click to check Diffusion-Mosaic.</span></font></a> 
</ul>



<ul>
<li><p><a href="https://arxiv.org/abs/2403.05416">  
SIRST-5K: Exploring Massive Negatives Synthesis with Self-supervised Learning for Robust Infrared Small Target Detection</a> <br />
<span style="text-decoration: underline;"> <a href="https://luy0222.github.io/">Yahao Lu*</a> </span>, Yupei Lin, Han Wu, Xiaoyu Xian, <b>Yukai Shi</b>, Liang Lin <br />
<i> IEEE Transactions on Geoscience and Remote Sensing  <b>(T-GRS)</b>, 2024. <a href="https://arxiv.org/abs/2403.05416">[PDF]</a> <a href="https://github.com/luy0222/SIRST-5K">[Code]</a><a href="https://zhuanlan.zhihu.com/p/686524491">[中文介绍]</a></i></p> 

</ul>




<ul>
<li><p><a href="https://arxiv.org/abs/2305.14669">	
NegVSR: Augmenting Negatives for Generalized Noise Modeling in Real-world Video Super-Resolution</a> <br />
<span style="text-decoration: underline;"> <a href="https://songyxing.github.io/">Yexing Song*</a> </span>, Meilin Wang, Zhijing Yang, Xiaoyu Xian, <b>Yukai Shi</b> <br />
<i> Proc. of AAAI Conference on Artificial Intelligence <b>(AAAI)</b>, 2024. <a href="https://arxiv.org/abs/2305.14669">[PDF]</a> <a href="https://github.com/NegVSR/NegVSR">[Code] <a href="https://negvsr.github.io/">[Demo]</i></p> 

</ul>


<ul>
<li><p><a href="https://arxiv.org/pdf/2312.09812.pdf">	
Structural Information Guided Multimodal Pre-training for Vehicle-centric Perception</a> <br />
Xiao Wang, Wentao Wu, Chenglong Li, Zhicheng Zhao, Zhe Chen, <b>Yukai Shi</b>, Jin Tang <br />
<i> Proc. of AAAI Conference on Artificial Intelligence <b>(AAAI)</b>, 2024. <a href="https://arxiv.org/pdf/2312.09812.pdf">[PDF]</a> <a href="https://github.com/Event-AHU/VehicleMAE">[Project Page]</i></a></p>
</li>
</ul>
 

<ul>
<li><p><a href="https://arxiv.org/html/2402.18172v1">  
NiteDR: Nighttime Image De-Raining with Cross-View Sensor Cooperative Learning for Dynamic Driving Scenes</a> <br />
<span style="text-decoration: underline;"> <a href="https://cidanshi.github.io/">Cidan Shi*</a> </span>, Lihuang Fang, Han Wu, Xiaoyu Xian, <b>Yukai Shi</b>, Liang Lin <br />
<i> IEEE Transactions on Multimedia <b>(T-MM)</b>, 2024. <a href="https://arxiv.org/html/2402.18172v1">[PDF]</a> <a href="https://github.com/CidanShi/NiteDR-Nighttime-Image-De-raining">[Code]</i></p>
</li>
</ul>



<ul>
<li><p><a href="https://export.arxiv.org/abs/2403.11870">  
IDF-CR: Iterative Diffusion Process for Divide-and-Conquer Cloud Removal in Remote-sensing Images</a> <br />
Meilin Wang, <span style="text-decoration: underline;"> <a href="https://songyxing.github.io/">Yexing Song*</a> </span>, Pengxu Wei, Xiaoyu Xian,<b>Yukai Shi</b>, Liang Lin  <br />
<i> IEEE Transactions on Geoscience and Remote Sensing  <b>(T-GRS)</b>, 2024. <a href="https://export.arxiv.org/abs/2403.11870">[PDF]</a>  <a href="https://github.com/SongYxing/IDF-CR">[Code]</a></i> </p> 
</li>
</ul>

<ul>
<li><p><a href="https://mirrordiffusion.github.io/">  
MirrorDiffusion: Stabilizing Diffusion Process in Zero-shot Image Translation by Prompts Redescription and Beyond</a> <br />
<span style="text-decoration: underline;"> <a href="https://yupeilin2388.github.io/">Yupei Lin*</a> </span>, Xiaoyu Xian, <b>Yukai Shi</b>, Liang Lin <br />
<i> IEEE Signal Processing Letters  <b>(SPL)</b>, 2024. <a href="https://arxiv.org/abs/2401.03221">[PDF]</a> <a href="https://mirrordiffusion.github.io/">[Project Page]</a> <a href="https://github.com/MirrorDiffusion/MirrorDiffusion">[Code]</i> </i></p>
</li>
</ul>

<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S095741742400335X">  
CROSE: Low-light Enhancement by CROss-SEnsor Interaction for Nighttime Driving Scenes</a> <br />
Xiaoyu Xian, Qi Zhou, Jinghui Qin, Xiaojun Yang, Yin Tian, <b>Yukai Shi</b>, Daxin Tian <br />
<i> Expert Systems with Applications <b>(ESWA)</b>, 2024. <a href="https://www.sciencedirect.com/science/article/abs/pii/S095741742400335X">[PDF]</i></a> </p> 
</li>
</ul>


  

<ul>
<li><p><a href="https://arxiv.org/abs/2301.00965">	
OccluMix: Towards De-Occlusion Virtual Try-on by Semantically-Guided Mixup</a> <br />
Zhijing Yang, <span style="text-decoration: underline;"> <a href="https://jychen9811.github.io/">Junyang Chen*</a> </span>,  <b>Yukai Shi</b>, Hao Li, Tianshui Chen, Liang Lin <br />
<i> IEEE Transactions on Multimedia <b>(T-MM)</b>, 2023. <a href="https://arxiv.org/abs/2301.00965">[PDF]</a> <a href="https://github.com/JyChen9811/DOC-VTON">[Code]</i></p>
</li>
</ul>


<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422019388">	
Reference-free Low-light Image Enhancement by Associating Hierarchical Wavelet Representations</a> <br />
Xiaojun Yang, Junhong Gong, Lianpei Wu, Zhijing Yang, <b>Yukai Shi</b>, Feiping Nie <br />
<i> Expert Systems with Applications <b>(ESWA)</b>, 2023. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422019388">[PDF]</a> </i></p>
</li>
</ul>




<ul>
<li><p><a href="https://arxiv.org/abs/2207.13861">DnSwin: Toward Real-World Denoising via Continuous Wavelet Sliding-Transformer</a> <br />
<span style="text-decoration: underline;"> <a href="https://house-leo.github.io/">Hao Li*</a> </span>, Zhijing Yang, Xiaobin Hong, Ziying Zhao, Junyang Chen, <b>Yukai Shi</b>, Jinshan Pan <br />
<i> Knowledge-Based Systems <b>(KBS)</b>, 2022. <a href="https://arxiv.org/abs/2207.13861">[PDF]</a> <a href="https://github.com/House-Leo/DnSwin">[Code]</a>  </i></p>
</li>
</ul>



<ul>
<li><p><a href="http://arxiv.org/abs/2207.12767">Criteria Comparative Learning for Real-scene Image Super-Resolution</a> <br />
<b>Yukai Shi</b>, Hao Li, Sen Zhang, Zhijing Yang, Xiao Wang <br />
<i> IEEE Transactions on Circuits and Systems for Video Technology <b>(T-CSVT)</b>, 2022. <a href="https://arxiv.org/pdf/2207.12767.pdf">[PDF]</a><a href="https://github.com/House-Leo/RealSR-CCL">[Code]</a><a href="https://github.com/House-Leo/RealSR-Zero">[RealSR-Zero]</a></i></p>
</li>
</ul>



<ul>
<li><p><a href="https://arxiv.org/pdf/2204.11018.pdf">Exploring Negatives in Contrastive Learning for Unpaired Image-to-Image Translation</a> <br />
<span style="text-decoration: underline;"> <a href="https://yupeilin2388.github.io/">Yupei Lin*</a> </span>, Sen Zhang, Tianshui Chen, Yongyi Lu, Guangping Li, <b>Yukai Shi</b> <br />
<i> ACM International Conference on Multimedia <b>(ACM MM)</b>, 2022. <a href="https://arxiv.org/abs/2204.11018v2">[PDF]</a><a href="https://github.com/Bite-The-Dust/Exploring-Negatives-in-Contrastive-Learning-for-Unpaired-Image-to-Image-Translation">[Code]</a></i></p>
</li>
</ul>



<ul>
<li><p><a href="https://github.com/House-Leo/RWSR-EDL">Real-World Image Super-Resolution by Exclusionary Dual-Learning</a> <br />
<span style="text-decoration: underline;"> <a href="https://house-leo.github.io/">Hao Li*</a> </span>, Jinghui Qin, Zhijing Yang, Pengxu Wei, Jinshan Pan, Liang Lin, <b>Yukai Shi</b> <br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2022. <a href="https://github.com/House-Leo/RWSR-EDL">[PDF]</a><a href="https://github.com/House-Leo/RWSR-EDL">[Code]</a></i></p>
</li>
</ul>




<ul>
<li><p><a href="https://arxiv.org/pdf/2008.09990">Unsupervised Multi-view Clustering by Squeezing Hybrid Knowledge from Cross View and Each View</a> <br />
Junpeng Tan*, <b>Yukai Shi</b>, Zhijing Yang, Caizhen Wen, Liang Lin <br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2021. <a href="https://arxiv.org/pdf/2008.09990">[PDF]</a></i></p>
</li>
</ul>



<ul>
<li><p><a href="https://arxiv.org/pdf/2102.00769">GTAE: Graph Transformer–Based Auto-Encoders for Linguistic-Constrained Text Style Transfer</a> <br />
<b>Yukai Shi</b>, Sen Zhang, Chenxing Zhou, Xiaodan Liang, Xiaojun Yang, Liang Lin <br />
<i>ACM Transactions on Intelligent Systems and Technology <b>(ACM T-IST)</b>, 2021. <a href="https://arxiv.org/pdf/2102.00769">[PDF]</a><a href="https://github.com/SenZHANG-GitHub/graph-text-style-transfer">[Code]</a><a href="https://github.com/ykshi/text-style-transfer-benchmark">[Benchmark]</a></i></p>
</li>
</ul>


<ul>
<li><p><a href="https://arxiv.org/pdf/1905.01509">Face Hallucination by Attentive Sequence Optimization with Reinforcement Learning</a> <br />
<b>Yukai Shi</b>, Guanbin Li, Qingxing Cao, Keze Wang, Liang Lin <br />
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(T-PAMI)</b>, 2020. <a href="https://arxiv.org/pdf/1905.01509">[PDF]</a><a href="https://github.com/ykshi/facehallucination">[Code]</a></i></p>
</li>
</ul>


<ul>
<li><p><a href="https://arxiv.org/pdf/1707.08340">Structure-preserving Image Super-resolution via Contextualized Multitask Learning</a> <br />
<b>Yukai Shi</b>, Keze Wang, Chongyu Chen, Li Xu, Liang Lin<br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2017. <a href="https://arxiv.org/pdf/1707.08340">[PDF]</a><a href="https://github.com/ykshi/SPNet">[Code]</a></i></p>
</li>
</ul>


<h2>Students' Achievements</h2>
<ul>
<li><p>[2024] National Scholarship (研究生国家奖学金) : <a href="https://yupeilin2388.github.io/">Yupei</a>, <a href="https://cidanshi.github.io/">Cidan</a> and <a href="https://songyxing.github.io/">Yexing</a> , Congrats! <br /> 
<li><p>[2023] National Scholarship (研究生国家奖学金) : <a href="https://jychen9811.github.io/">Junyang</a> <br /> 
</li>
</ul>

<h2>Alumni</h2>
<p><font size="1"> <b>*</b> I've collaborated with a lot of brilliant students, below is a partial list.</font></p>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-pl5h{font-family:Georgia, serif !important;font-size:15px;text-align:center;vertical-align:top}
.tg .tg-znrg{border-color:inherit;font-family:Georgia, serif !important;font-size:15px;text-align:center;vertical-align:top}
</style>
<table class="tg"><thead>
  <tr>
    <th class="tg-znrg">Name</th>
    <th class="tg-znrg">Year</th>
    <th class="tg-znrg">Thesis/Project</th>
    <th class="tg-znrg">Graduation TO</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-znrg">Junyang Chen</td>
    <td class="tg-znrg">2024</td>
    <td class="tg-znrg">Semantically-guided Virtual Try-on</td>
    <td class="tg-znrg">Ph.D@NJUST</td>
  </tr>
  <tr>
    <td class="tg-pl5h">Lihuang Fang</td>
    <td class="tg-pl5h">2024</td>
    <td class="tg-pl5h">Hyperspectral Data Fusion</td>
    <td class="tg-pl5h">Master@SUSTech</td>
  </tr>
  <tr>
    <td class="tg-pl5h">Junhong Gong</td>
    <td class="tg-pl5h">2024</td>
    <td class="tg-pl5h">Reference-free Low-light Enhancement</td>
    <td class="tg-pl5h">Digital Guangdong Co., Ltd.</td>
  </tr>
  <tr>
    <td class="tg-pl5h">Haoyu Zhong</td>
    <td class="tg-pl5h">2023</td>
    <td class="tg-pl5h">Real-world Image Super-Resolution</td>
    <td class="tg-pl5h">Xiaomi Corporation</td>
  </tr>
  <tr>
    <td class="tg-pl5h">Hao Li</td>
    <td class="tg-pl5h">2023</td>
    <td class="tg-pl5h">Real-world Image Processing</td>
    <td class="tg-pl5h">Ph.D@NJUST</td>
  </tr>
</tbody>
</table>


<br /> 

<div id="footer">
<div id="footer-text">
<br>Work from 2019-09-02, by Yukai Shi</a>.
</div>
</div>

</div>
</body>
</html>