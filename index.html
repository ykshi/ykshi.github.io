 <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>

<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />

<title>Yukai Shi (施煜锴) </title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Yukai Shi </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://ykshi.github.io/"><img src="picture/2.jpg" alt="alt text" width="140px" /></a>&nbsp;</td>
<td align="left"><p>Associate Professor <br />
School of Information Engineering <br />
Guangdong University of Technology <br />
Higher Education Mega Center <br />
Guangzhou 510006, China <br />
Email: ykshi.1991 [at] foxmail [dot] com <br />
<br />
<a href="https://scholar.google.com/citations?user=z_tI-X4AAAAJ&hl=zh-CN">[Google Scholar]</a> 
  <a href="https://github.com/ykshi">[GitHub]</a>
  <a href="https://orcid.org/0000-0002-9413-6528">[ORCiD]</a>
   </p> <br />
</td>

</tr></table>

<h2>Biography</h2>
<p>Currently Dr. SHI is a teacher at Guangdong University of Technology (GDUT). Before that, he graduated from Sun Yat-Sen University with a PhD degree, supervised by Prof. <a href="http://www.linliang.net/">[Liang Lin (林倞教授)]</a>. He was a visiting researcher in the University of Sydney and Microsoft Research Asia, worked with Prof.<a href="https://wlouyang.github.io/"> [Wanli Ouyang (欧阳万里教授)]</a> and Dr. <a href="https://jingdongwang2017.github.io/">[Jingdong Wang (王井东研究员)]</a>, respectively. He serves as a Reviewer for a number of journals and conferences, such as IJCV, IEEE T-PAMI, CVPR, ICCV, etc. </p> 

<p>Recently, almost all of my students have published top-tier conference/journal papers. In fact, all students in our group are talented, self-motivated and sometimes reliable. They own the most credit of following works which I was glad to work with.  </p>


<i>Never stop looking for collaboration, please feel free to contact me via email. (any question/suggestion/collaboration)</i>

<h2>Research Topic</h2>
<ul>
<li><p><b>AI Generated Content (AIGC)</b>: <a href="https://mirrordiffusion.github.io/">Diffusion Model for Fantasy Generation</a>,  <a href="https://github.com/YupeiLin2388/Diff-Mosaic">Vision Alignment and Augmentation.</a><br />
<li><p><b>Multimodality Sensing</b>: Cross-sensor Cooperative Sensing, Vision-Thermal Recognition, etc. <br />
<li><p><b>Computer Vision and Pattern Recognition</b>: Cross-data Vision Alignment, Data-centric Visual Learning, etc. <br />
</li>
</ul>

<h2>Selected Publications </h2> </b>
(<b>*</b> indicates supervised students) <a href="https://scholar.google.com/citations?user=z_tI-X4AAAAJ&hl=zh-CN">[Full Paper List]</a> 
<ul>
<li><p><a href="https://arxiv.org/abs/2507.18260">  
Exploiting Gaussian Agnostic Representation Learning with Diffusion Priors for Enhanced Infrared Small Target Detection</a> <br />
<span style="text-decoration: underline;"> <a href="https://datou0326.github.io/">Junyao Li*</a> </span>, Yahao Lu, Xingyuan Guo, Xiaoyu Xian, Tiantian Wang, <b>Yukai Shi</b> <br />
<i> ArXiv Preprint, 2025. <a href="https://arxiv.org/abs/2507.18260">[PDF]</a> <a href="https://github.com/ykshi">[Code](Coming soon)</a></i></p> 
</li><a href="https://arxiv.org/abs/2507.18260">
<font color="#FF0000">  We propose the Gaussian Group Squeezer, leveraging Gaussian sampling and compression with diffusion models, for agnostic representation learning.
</font></a> 
</ul>

<ul>
<li><p><a href="https://arxiv.org/abs/2504.16487">  
Rethinking Generalizable Infrared Small Target Detection: A Real-scene Benchmark and Cross-view Representation Learning</a> <br />
<span style="text-decoration: underline;"> <a href="https://luy0222.github.io/">Yahao Lu*</a> </span>, Yuehui Li, Xingyuan Guo, Shuai Yuan, <b>Yukai Shi</b>, Liang Lin <br />
<i> IEEE Transactions on Geoscience and Remote Sensing <b>(T-GRS)</b>, 2025. <a href="https://arxiv.org/abs/2504.16487">[PDF]</a> <a href="https://github.com/luy0222/RealScene-ISTD">[Code and Dataset]</a></i></p> 
</li><a href="https://github.com/luy0222/RealScene-ISTD">
<font color="#FF0000"> A benchmark associated with real-scene challenges for the Infrared Small Target Detection (ISTD) is presented
</font></a> 
</ul>

<ul>
<li><p><a href="https://arxiv.org/abs/2505.04526">  
DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once
</a> <br />
<span style="text-decoration: underline;"> <a href="https://davin-qi530.github.io/">Qi Zhou*</a> </span>, <b>Yukai Shi</b>, Xiaojun Yang, Xiaoyu Xian, Lunjia Liao, Ruimao Zhang, Liang Lin <br />
<i> IEEE Transactions on Instrumentation and Measurement<b> (T-IM)</b>, 2025. <a href="https://arxiv.org/abs/2505.04526">[PDF]</a> <a href="https://ykshi.github.io/">[Code]</a></i></p> 
</ul>

<ul>
<li><p><a href="https://arxiv.org/abs/2502.14493/">  
CrossFuse: Learning Infrared and Visible Image Fusion by Cross-Sensor Top-K Vision Alignment and Beyond</a> <br />
<b>Yukai Shi</b>, Cidan Shi, Zhipeng Weng, Yin Tian, Xiaoyu Xian, Liang Lin <br />
<i> IEEE Transactions on Circuits and Systems for Video Technology<b> (T-CSVT)</b>, 2025. <a href="https://arxiv.org/abs/2502.14493/">[PDF]</a> <a href="https://github.com/CidanShi/CrossFuse">[Code]</a></i></p> 
</ul>


<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/10974513/">  
Scaling Up Single Image Dehazing Algorithm by Cross-Data Vision Alignment and Beyond</a> <br />
<b>Yukai Shi</b>, <span style="text-decoration: underline;"> <a href="https://wengzp1.github.io/">Zhipeng Weng*</a> </span>, Yupei Lin, Cidan Shi, Xingyuan Guo, Xiaojun Yang, Liang Lin <br />
<i> IEEE Transactions on Instrumentation and Measurement<b> (T-IM)</b>, 2025. <a href="https://ieeexplore.ieee.org/abstract/document/10974513/">[PDF]</a> <a href="https://github.com/wengzp1/ScaleUpDehazing">[Code]</a></i></p> 
</ul>


<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/10906056">  
Boosting 3D Object Detection via Self-distilling Introspective Data</a> <br />
Chaoqun Wang, Yiran Qin, Zijian Kang, Ningning Ma, <b>Yukai Shi</b>, Zhen Li, Ruimao Zhang <br />
<i> IEEE Transactions on Intelligent Transportation Systems<b> (T-ITS)</b>, 2025. <a href="https://ieeexplore.ieee.org/abstract/document/10906056">[PDF]</a> <a href="https://github.com/chaoqunwangcs/SID">[Code]</a></i></p> 
</ul>


<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s11263-025-02358-x">  
Contrastive Decoupled Representation Learning and Regularization for Speech-Preserving Facial Expression Manipulation</a> <br />
Tianshui Chen, Jianman Lin, Zhijing Yang, Chumei Qing, <b>Yukai Shi</b>, Liang Lin <br />
<i> International Journal of Computer Vision<b> (IJCV)</b>, 2025. <a href="https://link.springer.com/article/10.1007/s11263-025-02358-x">[PDF]</a> </i></p> 
</ul>

<ul>
<li><p><a href="https://dl.acm.org/doi/abs/10.1145/3664647.3681017">  
Self-supervised emotion representation disentanglement for speech-preserving facial expression manipulation</a> <br />
Zhihua Xu, Tianshui Chen, Zhijing Yang, Chunmei Qing, <b>Yukai Shi</b>, Liang Lin <br />
<i> ACM International Conference on Multimedia<b> (ACM MM)</b>, 2025. <a href="https://dl.acm.org/doi/abs/10.1145/3664647.3681017">[PDF]</a> </i></p> 
</ul>


<ul>
<li><p><a href="https://github.com/YupeiLin2388/Diff-Mosaic">  
Diff-Mosaic: Augmenting Realistic Representations in Infrared Small Target Detection via Diffusion Prior</a> <br />
<b>Yukai Shi</b>, Yupei Lin, Pengxu Wei, Xiaoyu Xian, Tianshui Chen, Liang Lin <br />
<i> IEEE Transactions on Geoscience and Remote Sensing  <b>(T-GRS)</b>, 2024. <a href="https://github.com/YupeiLin2388/Diff-Mosaic">[PDF]</a> <a href="https://github.com/YupeiLin2388/Diff-Mosaic">[Code]</a></i></p> 

</ul>



<ul>
<li><p><a href="https://arxiv.org/abs/2403.05416">  
SIRST-5K: Exploring Massive Negatives Synthesis with Self-supervised Learning for Robust Infrared Small Target Detection</a> <br />
<span style="text-decoration: underline;"> <a href="https://luy0222.github.io/">Yahao Lu*</a> </span>, Yupei Lin, Han Wu, Xiaoyu Xian, <b>Yukai Shi</b>, Liang Lin <br />
<i> IEEE Transactions on Geoscience and Remote Sensing  <b>(T-GRS)</b>, 2024. <a href="https://arxiv.org/abs/2403.05416">[PDF]</a> <a href="https://github.com/luy0222/SIRST-5K">[Code]</a><a href="https://zhuanlan.zhihu.com/p/686524491">[中文介绍]</a></i></p> 

</ul>




<ul>
<li><p><a href="https://arxiv.org/abs/2305.14669">	
NegVSR: Augmenting Negatives for Generalized Noise Modeling in Real-world Video Super-Resolution</a> <br />
<span style="text-decoration: underline;"> <a href="https://songyxing.github.io/">Yexing Song*</a> </span>, Meilin Wang, Zhijing Yang, Xiaoyu Xian, <b>Yukai Shi</b> <br />
<i> Proc. of AAAI Conference on Artificial Intelligence <b>(AAAI)</b>, 2024. <a href="https://arxiv.org/abs/2305.14669">[PDF]</a> <a href="https://github.com/NegVSR/NegVSR">[Code] <a href="https://negvsr.github.io/">[Demo]</i></p> 

</ul>


<ul>
<li><p><a href="https://arxiv.org/pdf/2312.09812.pdf">	
Structural Information Guided Multimodal Pre-training for Vehicle-centric Perception</a> <br />
Xiao Wang, Wentao Wu, Chenglong Li, Zhicheng Zhao, Zhe Chen, <b>Yukai Shi</b>, Jin Tang <br />
<i> Proc. of AAAI Conference on Artificial Intelligence <b>(AAAI)</b>, 2024. <a href="https://arxiv.org/pdf/2312.09812.pdf">[PDF]</a> <a href="https://github.com/Event-AHU/VehicleMAE">[Project Page]</i></a></p>
</li>
</ul>
 

<ul>
<li><p><a href="https://arxiv.org/html/2402.18172v1">  
NiteDR: Nighttime Image De-Raining with Cross-View Sensor Cooperative Learning for Dynamic Driving Scenes</a> <br />
<span style="text-decoration: underline;"> <a href="https://cidanshi.github.io/">Cidan Shi*</a> </span>, Lihuang Fang, Han Wu, Xiaoyu Xian, <b>Yukai Shi</b>, Liang Lin <br />
<i> IEEE Transactions on Multimedia <b>(T-MM)</b>, 2024. <a href="https://arxiv.org/html/2402.18172v1">[PDF]</a> <a href="https://github.com/CidanShi/NiteDR-Nighttime-Image-De-raining">[Code]</i></p>
</li>
</ul>


<ul>
<li><p><a href="https://arxiv.org/pdf/2205.11131">  
Heterogeneous Semantic Transfer for Multi-label Recognition with Partial Labels</a> <br />
Tianshui Chen, Tao Pu, Lingbo Liu, <b>Yukai Shi</b>, Zhijing Yang, Liang Lin <br />
<i> International Journal of Computer Vision  <b>(IJCV)</b>, 2024. <a href="https://arxiv.org/pdf/2205.11131">[PDF]</a> <a href="https://github.com/HCPLab-SYSU/HCP-MLR-PL">[Code]</a><a href="https://mp.weixin.qq.com/s/oL7KKjKW3ZhCoXFIzxCJEg">[Media Report]</a></i></p> 
</ul>


<ul>
<li><p><a href="https://export.arxiv.org/abs/2403.11870">  
IDF-CR: Iterative Diffusion Process for Divide-and-Conquer Cloud Removal in Remote-sensing Images</a> <br />
Meilin Wang, <span style="text-decoration: underline;"> <a href="https://songyxing.github.io/">Yexing Song*</a> </span>, Pengxu Wei, Xiaoyu Xian,<b>Yukai Shi</b>, Liang Lin  <br />
<i> IEEE Transactions on Geoscience and Remote Sensing  <b>(T-GRS)</b>, 2024. <a href="https://export.arxiv.org/abs/2403.11870">[PDF]</a>  <a href="https://github.com/SongYxing/IDF-CR">[Code]</a></i> </p> 
</li>
</ul>

<ul>
<li><p><a href="https://mirrordiffusion.github.io/">  
MirrorDiffusion: Stabilizing Diffusion Process in Zero-shot Image Translation by Prompts Redescription and Beyond</a> <br />
<span style="text-decoration: underline;"> <a href="https://yupeilin2388.github.io/">Yupei Lin*</a> </span>, Xiaoyu Xian, <b>Yukai Shi</b>, Liang Lin <br />
<i> IEEE Signal Processing Letters  <b>(SPL)</b>, 2024. <a href="https://arxiv.org/abs/2401.03221">[PDF]</a> <a href="https://mirrordiffusion.github.io/">[Project Page]</a> <a href="https://github.com/MirrorDiffusion/MirrorDiffusion">[Code]</i> </i></p>
</li>
</ul>

<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S095741742400335X">  
CROSE: Low-light Enhancement by CROss-SEnsor Interaction for Nighttime Driving Scenes</a> <br />
Xiaoyu Xian*, Qi Zhou*, Jinghui Qin, Xiaojun Yang, Yin Tian, <b>Yukai Shi</b>, Daxin Tian <br />
<i> Expert Systems with Applications <b>(ESWA)</b>, 2024. <a href="https://www.sciencedirect.com/science/article/abs/pii/S095741742400335X">[PDF]</i></a> </p> 
</li>
</ul>



<ul>
<li><p><a href="https://arxiv.org/abs/2301.00965">	
OccluMix: Towards De-Occlusion Virtual Try-on by Semantically-Guided Mixup</a> <br />
Zhijing Yang, <span style="text-decoration: underline;"> <a href="https://jychen9811.github.io/">Junyang Chen*</a> </span>,  <b>Yukai Shi</b>, Hao Li, Tianshui Chen, Liang Lin <br />
<i> IEEE Transactions on Multimedia <b>(T-MM)</b>, 2023. <a href="https://arxiv.org/abs/2301.00965">[PDF]</a> <a href="https://github.com/JyChen9811/DOC-VTON">[Code]</i></p>
</li>
</ul>


<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422019388">	
Reference-free Low-light Image Enhancement by Associating Hierarchical Wavelet Representations</a> <br />
Xiaojun Yang, Junhong Gong, Lianpei Wu, Zhijing Yang, <b>Yukai Shi</b>, Feiping Nie <br />
<i> Expert Systems with Applications <b>(ESWA)</b>, 2023. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422019388">[PDF]</a> </i></p>
</li>
</ul>




<ul>
<li><p><a href="https://arxiv.org/abs/2207.13861">DnSwin: Toward Real-World Denoising via Continuous Wavelet Sliding-Transformer</a> <br />
<span style="text-decoration: underline;"> <a href="https://house-leo.github.io/">Hao Li*</a> </span>, Zhijing Yang, Xiaobin Hong, Ziying Zhao, Junyang Chen, <b>Yukai Shi</b>, Jinshan Pan <br />
<i> Knowledge-Based Systems <b>(KBS)</b>, 2022. <a href="https://arxiv.org/abs/2207.13861">[PDF]</a> <a href="https://github.com/House-Leo/DnSwin">[Code]</a>  </i></p>
</li>
</ul>



<ul>
<li><p><a href="http://arxiv.org/abs/2207.12767">Criteria Comparative Learning for Real-scene Image Super-Resolution</a> <br />
<b>Yukai Shi</b>, Hao Li, Sen Zhang, Zhijing Yang, Xiao Wang <br />
<i> IEEE Transactions on Circuits and Systems for Video Technology <b>(T-CSVT)</b>, 2022. <a href="https://arxiv.org/pdf/2207.12767.pdf">[PDF]</a><a href="https://github.com/House-Leo/RealSR-CCL">[Code]</a><a href="https://github.com/House-Leo/RealSR-Zero">[RealSR-Zero]</a></i></p>
</li>
</ul>



<ul>
<li><p><a href="https://arxiv.org/pdf/2204.11018.pdf">Exploring Negatives in Contrastive Learning for Unpaired Image-to-Image Translation</a> <br />
<span style="text-decoration: underline;"> <a href="https://yupeilin2388.github.io/">Yupei Lin*</a> </span>, Sen Zhang, Tianshui Chen, Yongyi Lu, Guangping Li, <b>Yukai Shi</b> <br />
<i> ACM International Conference on Multimedia <b>(ACM MM)</b>, 2022. <a href="https://arxiv.org/abs/2204.11018v2">[PDF]</a><a href="https://github.com/Bite-The-Dust/Exploring-Negatives-in-Contrastive-Learning-for-Unpaired-Image-to-Image-Translation">[Code]</a></i></p>
</li>
</ul>



<ul>
<li><p><a href="https://github.com/House-Leo/RWSR-EDL">Real-World Image Super-Resolution by Exclusionary Dual-Learning</a> <br />
<span style="text-decoration: underline;"> <a href="https://house-leo.github.io/">Hao Li*</a> </span>, Jinghui Qin, Zhijing Yang, Pengxu Wei, Jinshan Pan, Liang Lin, <b>Yukai Shi</b> <br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2022. <a href="https://github.com/House-Leo/RWSR-EDL">[PDF]</a><a href="https://github.com/House-Leo/RWSR-EDL">[Code]</a></i></p>
</li>
</ul>




<ul>
<li><p><a href="https://arxiv.org/pdf/2008.09990">Unsupervised Multi-view Clustering by Squeezing Hybrid Knowledge from Cross View and Each View</a> <br />
Junpeng Tan*, <b>Yukai Shi</b>, Zhijing Yang, Caizhen Wen, Liang Lin <br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2021. <a href="https://arxiv.org/pdf/2008.09990">[PDF]</a></i></p>
</li>
</ul>



<ul>
<li><p><a href="https://arxiv.org/pdf/2102.00769">GTAE: Graph Transformer–Based Auto-Encoders for Linguistic-Constrained Text Style Transfer</a> <br />
<b>Yukai Shi</b>, Sen Zhang, Chenxing Zhou, Xiaodan Liang, Xiaojun Yang, Liang Lin <br />
<i>ACM Transactions on Intelligent Systems and Technology <b>(ACM T-IST)</b>, 2021. <a href="https://arxiv.org/pdf/2102.00769">[PDF]</a><a href="https://github.com/SenZHANG-GitHub/graph-text-style-transfer">[Code]</a><a href="https://github.com/ykshi/text-style-transfer-benchmark">[Benchmark]</a></i></p>
</li>
</ul>


<ul>
<li><p><a href="https://arxiv.org/pdf/1905.01509">Face Hallucination by Attentive Sequence Optimization with Reinforcement Learning</a> <br />
<b>Yukai Shi</b>, Guanbin Li, Qingxing Cao, Keze Wang, Liang Lin <br />
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(T-PAMI)</b>, 2020. <a href="https://arxiv.org/pdf/1905.01509">[PDF]</a><a href="https://github.com/ykshi/facehallucination">[Code]</a></i></p>
</li>
</ul>


<ul>
<li><p><a href="https://arxiv.org/pdf/1707.08340">Structure-preserving Image Super-resolution via Contextualized Multitask Learning</a> <br />
<b>Yukai Shi</b>, Keze Wang, Chongyu Chen, Li Xu, Liang Lin<br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2017. <a href="https://arxiv.org/pdf/1707.08340">[PDF]</a><a href="https://github.com/ykshi/SPNet">[Code]</a></i></p>
</li>
</ul>


<h2>Students' Achievements</h2>
<ul>
<li><p>[2025] National Scholarship (+3): <a href="https://luy0222.github.io/">Yahao Lu</a>, Yuehui Li, <a href="https://wengzp1.github.io/">Zhipeng Weng</a>,  congrats! <br /> 
<li><p>[2024] National Scholarship (+3): <a href="https://yupeilin2388.github.io/">Yupei Lin</a>, <a href="https://cidanshi.github.io/">Cidan Shi</a> and <a href="https://songyxing.github.io/">Yexing Song</a><br /> 
<li><p>[2023] National Scholarship (Highest Scholarship in China) : <a href="https://jychen9811.github.io/">Junyang Chen.</a> <br /> 
</li>
</ul>

<h2>Alumni</h2>
<p><font size="1"> <b>*</b> This is a partial list.</font></p>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-pl5h{font-family:Georgia, serif !important;font-size:15px;text-align:center;vertical-align:top}
.tg .tg-znrg{border-color:inherit;font-family:Georgia, serif !important;font-size:15px;text-align:center;vertical-align:top}
</style>
<table class="tg"><thead>
  <tr>
    <th class="tg-znrg">Name</th>
    <th class="tg-znrg">Year</th>
    <th class="tg-znrg">Thesis/Project</th>
    <th class="tg-znrg">Graduation TO</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-znrg"><a href="https://yupeilin2388.github.io/">Yupei Lin</a></td>
    <td class="tg-znrg">2025</td>
    <td class="tg-znrg">Controlled Content Generation</td>
    <td class="tg-znrg">Ph.D@SYSU</td>
  </tr>
  <tr>
    <td class="tg-znrg"><a href="https://songyxing.github.io/">Yexing Song</a></td>
    <td class="tg-znrg">2025</td>
    <td class="tg-znrg">Video Super-Resolution</td>
    <td class="tg-znrg">Tencent</td>
  </tr>
  <tr>
    <td class="tg-znrg"><a href="https://cidanshi.github.io/">Cidan Shi</a></td>
    <td class="tg-znrg">2025</td>
    <td class="tg-znrg">Image De-Raining and Fusion</td>
    <td class="tg-znrg">Research Institute, Guangri Co., LTD. </td>
  </tr>
  <tr>
    <td class="tg-znrg"><a href="https://jychen9811.github.io/">Junyang Chen</a></td>
    <td class="tg-znrg">2024</td>
    <td class="tg-znrg">Semantically-Guided Virtual Try-on</td>
    <td class="tg-znrg">Ph.D@NJUST</td>
  </tr>
  <tr>
    <td class="tg-pl5h">Lihuang Fang</td>
    <td class="tg-pl5h">2024</td>
    <td class="tg-pl5h">Hyperspectral Data Fusion</td>
    <td class="tg-pl5h">Master@SUSTech</td>
  </tr>
  <tr>
    <td class="tg-pl5h">Junhong Gong</td>
    <td class="tg-pl5h">2024</td>
    <td class="tg-pl5h">Reference-free Low-light Enhancement</td>
    <td class="tg-pl5h">Digital Guangdong Co., Ltd.</td>
  </tr>
  <tr>
    <td class="tg-pl5h">Haoyu Zhong</td>
    <td class="tg-pl5h">2023</td>
    <td class="tg-pl5h">Real-world Image Super-Resolution</td>
    <td class="tg-pl5h">Xiaomi Corporation</td>
  </tr>
  <tr>
    <td class="tg-pl5h"> <a href="https://house-leo.github.io/">Hao Li</a></td>
    <td class="tg-pl5h">2023</td>
    <td class="tg-pl5h">Real-world Image Processing</td>
    <td class="tg-pl5h">Ph.D@NJUST</td>
  </tr>
</tbody>
</table>


<br /> 

<div id="footer">
<div id="footer-text">
<br>Work from 2019-09-02, by Yukai Shi</a>.
</div>
</div>

</div>
</body>
</html>