 <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yukai Shi</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Yukai Shi</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://ykshi.github.io/"><img src="picture/123.jpg" alt="alt text" width="120px" /></a>&nbsp;</td>
<td align="left"><p>Lecturer<br />
School of Information Engineering <br />
Guangdong University of Technology <br />
Higher Education Mega Center <br />
Guangzhou 510006, China <br />
Email: ykshi.1991 AT foxmail DOT com <br />
<br />
<a href="https://scholar.google.com/citations?user=z_tI-X4AAAAJ&hl=zh-CN">[Google Scholar]</a> 
  <a href="https://github.com/ykshi">[GitHub]</a>
  <a href="https://orcid.org/0000-0002-9413-6528">[ORCiD]</a>
   </p> <br />
</td>

</tr></table>

<h2>Biography</h2>
<p>Currently I am a lecturer at Guangdong University of Technology (GDUT). Before that, I graduated from Sun Yat-Sen University with a PhD
degree, supervised by <a href="http://www.linliang.net/">Prof. Liang Lin</a>, I was a visiting student in the University of Sydney and Microsoft Research Asia,
worked with <a href="https://wlouyang.github.io/">Prof. Wanli Ouyang</a> and <a href="https://jingdongwang2017.github.io/">Dr. Jingdong Wang</a>, respectively. 

<p>My research topic focus on real-world image processing and its applications. </p>

<h2>Publications</h2>
(* indicates supervised/cosupervised students)

<ul>
<li><p><a href="https://ykshi.github.io/">	
OccluMix: Towards De-Occlusion Virtual Try-on by Semantically-Guided Mixup</a> <br />
Zhijing Yang, <span style="text-decoration: underline;"> <a href="https://jychen9811.github.io/">Junyang Chen*</a> </span>,  <b>Yukai Shi</b>, Hao Li, Tianshui Chen, Liang Lin <br />
<i> IEEE Transactions on Multimedia <b>(TMM)</b>, 2023. <a href="https://ykshi.github.io/">[PDF]</a> [Code] (Coming Soon)</i></p>
</li>
</ul>

<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422019388">	
Reference-free Low-light Image Enhancement by Associating Hierarchical Wavelet Representations</a> <br />
Xiaojun Yang, Junhong Gong*, Lianpei Wu*, Zhijing Yang, <b>Yukai Shi</b>, Feiping Nie <br />
<i> Expert Systems with Applications <b>(ESWA)</b>, 2023. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422019388">[PDF]</a> </i></p>
</li>
</ul>


<ul>
<li><p><a href="https://arxiv.org/abs/2207.13861">Scale-Aware Squeeze-and-Excitation for Lightweight Object Detection</a> <br />
Zhihua Xu, Xiaobin Hong, Tianshui Chen, Zhijing Yang, <b>Yukai Shi</b> <br />
<i> IEEE Robotics and Automation Letters <b>(RA-L)</b>, 2022. <a href="https://ieeexplore.ieee.org/abstract/document/9954135">[PDF]</a> </i></p>
</li>
</ul>


<ul>
<li><p><a href="https://arxiv.org/abs/2207.13861">DnSwin: Toward Real-World Denoising via Continuous Wavelet Sliding-Transformer</a> <br />
Hao Li*, Zhijing Yang, Xiaobin Hong, Ziying Zhao, Junyang Chen, <b>Yukai Shi</b>, Jinshan Pan <br />
<i> Knowledge-Based Systems <b>(KBS)</b>, 2022. <a href="https://arxiv.org/abs/2207.13861">[PDF]</a> <a href="https://github.com/House-Leo/DnSwin">[Code]</a>  </i></p>
</li>
<font color="#FF0000">Wavelet downsampling expands window size in Transformer cheaply for a better real-world denoising</font> 
</ul>



<ul>
<li><p><a href="http://arxiv.org/abs/2207.12767">Criteria Comparative Learning for Real-scene Image Super-Resolution</a> <br />
<b>Yukai Shi</b>, Hao Li, <span style="text-decoration: underline;"> <a href="https://scholar.google.com/citations?user=-bJJNV0AAAAJ&hl=zh-CN&oi=ao">Sen Zhang</a> </span>, Zhijing Yang, Xiao Wang <br />
<i> IEEE Transactions on Circuits and Systems for Video Technology <b>(T-CSVT)</b>, 2022. <a href="https://arxiv.org/pdf/2207.12767.pdf">[PDF]</a><a href="https://github.com/House-Leo/RealSR-CCL">[Code]</a><a href="https://github.com/House-Leo/RealSR-Zero">[RealSR-Zero]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/pdf/2204.11018.pdf">Exploring Negatives in Contrastive Learning for Unpaired Image-to-Image Translation</a> <br />
Yupei Lin*, Sen Zhang, Tianshui Chen, Yongyi Lu, Guangping Li, <b>Yukai Shi</b> <br />
<i> ACM International Conference on Multimedia <b>(ACM MM)</b>, 2022. <a href="https://arxiv.org/abs/2204.11018v2">[PDF]</a><a href="https://github.com/Bite-The-Dust/Exploring-Negatives-in-Contrastive-Learning-for-Unpaired-Image-to-Image-Translation">[Code]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://github.com/House-Leo/RWSR-EDL">Real-World Image Super-Resolution by Exclusionary Dual-Learning</a> <br />
<span style="text-decoration: underline;"> <a href="https://house-leo.github.io/">Hao Li*</a> </span>, Jinghui Qin, Zhijing Yang, Pengxu Wei, Jinshan Pan, Liang Lin, <b>Yukai Shi</b> <br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2022. <a href="https://github.com/House-Leo/RWSR-EDL">[PDF]</a><a href="https://github.com/House-Leo/RWSR-EDL">[Code]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422013756">DFAEN: Double-Order Knowledge Fusion and Attentional Encoding Network for Texture Recognition</a> <br />
Zhijing Yang, Shujian Lai, Xiaobin Hong, <b>Yukai Shi</b>, Yongqiang Cheng, Chunmei Qing <br />
<i> Expert Systems with Applications  <b>(ESWA)</b>, 2022. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422013756/">[PDF]</a></i></p>
</li>
</ul>
 
<ul>
<li><p><a href="https://arxiv.org/pdf/2102.00769">GTAE: Graph Transformerâ€“Based Auto-Encoders for Linguistic-Constrained Text Style Transfer</a> <br />
<b>Yukai Shi</b>, Sen Zhang, Chenxing Zhou, Xiaodan Liang, Xiaojun Yang, Liang Lin <br />
<i>ACM Transactions on Intelligent Systems and Technology <b>(ACM T-IST)</b>, 2021. <a href="https://arxiv.org/pdf/2102.00769">[PDF]</a><a href="https://github.com/SenZHANG-GitHub/graph-text-style-transfer">[Code]</a><a href="https://github.com/ykshi/text-style-transfer-benchmark">[Benchmark]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/pdf/2008.09990">Unsupervised Multi-view Clustering by Squeezing Hybrid Knowledge from Cross View and Each View</a> <br />
Junpeng Tan*, <b>Yukai Shi</b>, Zhijing Yang, Caizhen Wen, Liang Lin <br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2021. <a href="https://arxiv.org/pdf/2008.09990">[PDF]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/pdf/2002.11079">DDet: Dual-path Dynamic Enhancement Network for Real-world Image Ruper-resolution</a> <br />
<b>Yukai Shi</b>, Haoyu Zhong, Zhijing Yang, Xiaojun Yang, Liang Lin <br />
<i>IEEE Signal Processing Letters <b>(SPL)</b>, 2020. <a href="https://arxiv.org/pdf/2002.11079">[PDF]</a> <a href="https://github.com/ykshi/DDet">[Code]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/pdf/1905.01509">Face Hallucination by Attentive Sequence Optimization with Reinforcement Learning</a> <br />
<b>Yukai Shi</b>, Guanbin Li, Qingxing Cao, Keze Wang, Liang Lin <br />
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(T-PAMI)</b>, 2020. <a href="https://arxiv.org/pdf/1905.01509">[PDF]</a><a href="https://github.com/ykshi/facehallucination">[Code]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/pdf/1904.05802">Difficulty-aware Image Super Resolution via Deep Adaptive Dual-Network</a> <br />
Jinghui Qin, Ziwei Xie, <b>Yukai Shi</b>, Wushao Wen <br />
<i>IEEE International Conference on Multimedia and Expo <b>(ICME)</b>, Oral, 2019. <a href="https://arxiv.org/pdf/1904.05802">[PDF]</a><a href="https://github.com/xzwlx/Difficulty-SR">[Code]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/pdf/1707.08340">Structure-preserving Image Super-resolution via Contextualized Multitask Learning</a> <br />
<b>Yukai Shi</b>, Keze Wang, Chongyu Chen, Li Xu, Liang Lin<br />
<i>IEEE Transactions on Multimedia <b>(T-MM)</b>, 2017. <a href="https://arxiv.org/pdf/1707.08340">[PDF]</a><a href="https://github.com/ykshi/SPNet">[Code]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Cao_Attention-Aware_Face_Hallucination_CVPR_2017_paper.pdf">Attention-aware Face Hallucination via Deep Reinforcement Learning</a> <br />
Qingxing Cao, Liang Lin, <b>Yukai Shi</b>, Xiaodan Liang, Guanbin Li <br />
<i>IEEE International Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2017. <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Cao_Attention-Aware_Face_Hallucination_CVPR_2017_paper.pdf">[PDF]</a><a href="https://github.com/ykshi/facehallucination">[Code]</a></i></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/pdf/1607.07220">Local- and Holistic-structure Preserving Image Super Resolution via Deep Joint Component Learning</a> <br />
<b>Yukai Shi</b>, Keze Wang, Li Xu, Liang Lin<br />
<i>IEEE Conference on Multimedia and Expo <b>(ICME)</b>, Oral, 2016. <a href="https://arxiv.org/pdf/1607.07220">[PDF]</a><a href="https://github.com/ykshi/SPNet">[Code]</a></i></p>
</li>
</ul>

<h2>Awards</h2>
<ul>
<li><p>2020-2021, Challenger, Honor of Kings <br />
<li><p>2016-2017, Excellent Graduate Scholarship, Sun Yat-sen University <br />
<li><p>2016-2017, The school's second-class scholarship, Sun Yat-sen University <br />
</li>
</ul>
<div id="footer">
<div id="footer-text">
<br>Page generated 2022-01-19, by <a href="https://ykshi.github.io/">Yukai Shi</a>.
</div>
</div>
</div>
</body>
</html>